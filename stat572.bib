@Book{Karlin1975,
  author = 	 {S. Karlin and H.M. Taylor},
  title = 	 {A First Course in Stochastic Processes},
  publisher = 	 {Academic Press},
  year = 	 {1975},
  edition =      {2nd}
}

@ARTICLE{Friedman2008-oq,
  title       = "Sparse inverse covariance estimation with the graphical lasso",
  author      = "Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert",
  affiliation = "Department of Statistics, Stanford University, CA 94305, USA.",
  abstract    = "We consider the problem of estimating sparse graphs by a lasso
                 penalty applied to the inverse covariance matrix. Using a
                 coordinate descent procedure for the lasso, we develop a
                 simple algorithm--the graphical lasso--that is remarkably
                 fast: It solves a 1000-node problem ( approximately 500,000
                 parameters) in at most a minute and is 30-4000 times faster
                 than competing methods. It also provides a conceptual link
                 between the exact problem and the approximation suggested by
                 Meinshausen and B{\"{u}}hlmann (2006). We illustrate the
                 method on some cell-signaling data from proteomics.",
  journal     = "Biostatistics",
  volume      =  9,
  number      =  3,
  pages       = "432--441",
  month       =  jul,
  year        =  2008
}

@ARTICLE{Meinshausen2006-fx,
  title         = "High-dimensional graphs and variable selection with the
                   Lasso",
  author        = "Meinshausen, Nicolai and B{\"{u}}hlmann, Peter",
  abstract      = "The pattern of zero entries in the inverse covariance matrix
                   of a multivariate normal distribution corresponds to
                   conditional independence restrictions between variables.
                   Covariance selection aims at estimating those structural
                   zeros from data. We show that neighborhood selection with
                   the Lasso is a computationally attractive alternative to
                   standard covariance selection for sparse high-dimensional
                   graphs. Neighborhood selection estimates the conditional
                   independence restrictions separately for each node in the
                   graph and is hence equivalent to variable selection for
                   Gaussian linear models. We show that the proposed
                   neighborhood selection scheme is consistent for sparse
                   high-dimensional graphs. Consistency hinges on the choice of
                   the penalty parameter. The oracle value for optimal
                   prediction does not lead to a consistent neighborhood
                   estimate. Controlling instead the probability of falsely
                   joining some distinct connectivity components of the graph,
                   consistent estimation for sparse graphs is achieved (with
                   exponential rates), even when the number of variables grows
                   as the number of observations raised to an arbitrary power.",
  month         =  "1~" # aug,
  year          =  2006,
  archivePrefix = "arXiv",
  primaryClass  = "math.ST",
  eprint        = "math/0608017"
}


@ARTICLE{Yang2013-md,
  title         = "On Graphical Models via Univariate Exponential Family
                   Distributions",
  author        = "Yang, Eunho and Ravikumar, Pradeep and Allen, Genevera I and
                   Liu, Zhandong",
  abstract      = "Undirected graphical models, or Markov networks, are a
                   popular class of statistical models, used in a wide variety
                   of applications. Popular instances of this class include
                   Gaussian graphical models and Ising models. In many
                   settings, however, it might not be clear which subclass of
                   graphical models to use, particularly for non-Gaussian and
                   non-categorical data. In this paper, we consider a general
                   sub-class of graphical models where the node-wise
                   conditional distributions arise from exponential families.
                   This allows us to derive multivariate graphical model
                   distributions from univariate exponential family
                   distributions, such as the Poisson, negative binomial, and
                   exponential distributions. Our key contributions include a
                   class of M-estimators to fit these graphical model
                   distributions; and rigorous statistical analysis showing
                   that these M-estimators recover the true graphical model
                   structure exactly, with high probability. We provide
                   examples of genomic and proteomic networks learned via
                   instances of our class of graphical models derived from
                   Poisson and exponential distributions.",
  month         =  "17~" # jan,
  year          =  2013,
  archivePrefix = "arXiv",
  primaryClass  = "math.ST",
  eprint        = "1301.4183"
}


@ARTICLE{LauWer89,
  title = "{LauWer89\_Graphical\_models.pdf}"
}



@MISC{Bento2011-vw,
  title  = "Which graphical models are difficult to learn?",
  author = "Bento, Jose and Montanari, Andrea",
  year   =  2011
}



@Article{Baum1970,
  author = 	 {L.E. Baum and T. Petrie and G. Soules and N. Weiss},
  title = 	 {A maximization technique occurring in the statistical analysis of probilistic functions of {M}arkov chains},
  journal = 	 {Annals of Mathematical Statistics},
  year = 	 1970,
  volume = 	 41,
  pages = 	 {164--171}
}